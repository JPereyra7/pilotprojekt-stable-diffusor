
# ğŸ§  AI Room Editor â€” Pilotprojekt

ğŸš€ Deployment lÃ¤nk: https://stable-diffusor-joelp.netlify.app/

Detta Ã¤r ett experimentellt projekt som anvÃ¤nder generativ AI fÃ¶r att placera anvÃ¤ndaruppladdade objekt (som mattor) in i AI-genererade bilder av rum. Projektet bygger pÃ¥ en kombination av:

- ğŸ§± **Stable Diffusion v1.5** â€“ fÃ¶r att generera grundlÃ¤ggande rumsmiljÃ¶er.
- ğŸ§  **ControlNet (Kandinsky 2.2 Depth)** â€“ fÃ¶r att fÃ¶rsÃ¶ka placera in en uppladdad bild i scenen baserat pÃ¥ djupinformation.
- â˜ï¸ **Supabase** â€“ fÃ¶r autentisering och filuppladdningar.
- ğŸ’» **Next.js (App Router)** â€“ fÃ¶r frontend + API-routes som kommunicerar med Replicate.
- ğŸ–¼ï¸ **Replicate API** â€“ fÃ¶r att kÃ¶ra modeller via REST.

---

## ğŸ“¦ Installation

```bash
git clone https://github.com/JPereyra7/pilotprojekt-stable-diffusor.git
cd pilotprojekt-stable-diffusor
npm install
```

### ğŸ” MiljÃ¶variabler

Skapa en `.env.local` och lÃ¤gg till fÃ¶ljande:

```env
NEXT_PUBLIC_SUPABASE_URL=your_supabase_url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_anon_key
NEXT_PUBLIC_MODELSLAB_KEY=your_modelslab_key
REPLICATE_API_TOKEN=your_replicate_token
```

---

## ğŸš€ Starta projektet lokalt

```bash
npm run dev
```

---

## âš ï¸ BegrÃ¤nsningar

- Modellerna har begrÃ¤nsad fÃ¶rmÃ¥ga att exakt placera ett specifikt objekt i en befintlig bild.
- Replicate krÃ¤ver **betald kreditering** fÃ¶r att kÃ¶ra vissa modeller.
- Resultaten kan ibland vara ofÃ¶rutsÃ¤gbara dÃ¥ vissa modeller "hallucinerar" innehÃ¥ll istÃ¤llet fÃ¶r att fÃ¶lja instruktioner strikt.
- Detta Ã¤r ett pilotprojekt och inte optimerat fÃ¶r produktion.

---

## ğŸ”® NÃ¤sta steg

- UtvÃ¤rdera lokala lÃ¶sningar med ComfyUI eller Automatic1111 fÃ¶r bÃ¤ttre precision vid inpainting.
- Implementera image masking via ControlNet.
- MÃ¶jliggÃ¶ra anvÃ¤ndarinteraktion fÃ¶r att rita egna maskomrÃ¥den.

---

## ğŸ“„ Licens

MIT
